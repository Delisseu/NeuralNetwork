## Сравнение с PyTorch

Я протестировал простую CNN на MNIST (10 эпох).

**Результаты:**

- Использовано VRAM (GPU):
    - CuPy NN: **0.66 GB**
    - PyTorch: **3.21 GB**
- Время обучения (10 эпох):
    - CuPy NN: **15.60 s**
    - PyTorch: **9.65 s**
- Forward + Backward (1 sample):
    - CuPy NN: forward **0.00222 s**, backward **0.01688 s**
    - PyTorch: forward **0.00411 s**, backward **0.00903 s**

График сходимости (`loss` по эпохам):

![loss_comparison](./examples/compare_loss.png)

Вывод:

- Обе реализации показывают **одинаковую тенденцию сходимости**.
- PyTorch ожидаемо быстрее на backward, за счёт высоко оптимизированных CUDA-ядер.
- Кастомная реализация экономит VRAM, что делает ее более масштабируемой, где разница в скорости стремится к нулю.

---

## Особенности реализации

1. **Conv2D → Dense и PyTorch:**  
   При полной проверке `conv2d -> dense` с фиксированными весами возможны расхождения из-за разного формата данных:
    - В этой библиотеке: `(B, H, W, C)`
    - В PyTorch: `(B, C, H, W)`  
      Это **не влияет на сходимость**, а при корректном `reshape` обе реализации совпадают.

2. **Нормализации** можно использовать и внутри слоёв, и как отдельный слой.

3. **Ускорение через flatten в conv2d:** при умножении патчей на kernels используется `flatten` → матричные умножения
   работают быстрее.

4. **Train vs Inference:**
    - `train=True` → сохраняются матрицы для backprop.
    - `train=False` → они не сохраняются (экономия VRAM).  
      ⚠️ Поэтому после `forward(train=False)` нельзя вызывать `backward`.

5. **Активации и нормализации внутри слоёв:**  
   Это сделано специально, чтобы конфигурации сетей оставались компактными.

6. **MultiConvAttention:**  
   Является чисто экспериментом.

7. **Schedulers:**  
   Оптимизаторы поддерживают расписания обучения (`InverseSqrtScheduler`, модификации и др.).

8. **Автоматическая инициализация:**  
   Основной класс `NeuralNetwork` сам подбирает корректные входные параметры для слоёв (в большинстве случаев), поэтому
   нет нужды на каждом слою прописывать `input_dim`.

---

При установке cupy и torch обязательно использовать версии совместимые с cuda.
Например:
```bash
pip install cupy-cuda12x
```` 
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu126
````

Установить зависимости для использования библиотеки:
```bash
pip install -r requirements.txt
```
Установить зависимости для использования библиотеки + сравнения с torch:
```bash
pip install -r requirements-dev.txt
```